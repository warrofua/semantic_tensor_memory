#!/usr/bin/env python3
"""
Demo Dataset Loader for Semantic Tensor Memory Analysis

This script demonstrates the power of semantic tensor memory analysis using
a carefully crafted dataset showing a person's journey from career dissatisfaction
to becoming a researcher in AI and computational neuroscience.

The dataset showcases:
- Clear semantic evolution over time
- Vocabulary development (accounting â†’ Python â†’ ML â†’ neuroscience)
- Emotional progression (lost â†’ excited â†’ confident â†’ visionary)
- Conceptual complexity growth
- Natural phase transitions with semantic shifts
"""

from datetime import datetime
from importlib import resources

import pandas as pd
import streamlit as st

def load_demo_dataset():
    """Load the demonstration dataset and return analysis insights."""
    
    # Load the dataset
    with resources.as_file(resources.files("data").joinpath("demo_dataset.csv")) as dataset_path:
        df = pd.read_csv(dataset_path)
    
    # Convert timestamps to readable dates
    df['date'] = pd.to_datetime(df['timestamp'], unit='s')
    df['formatted_date'] = df['date'].dt.strftime('%Y-%m-%d')
    
    # Add analysis metadata
    analysis_insights = {
        'total_sessions': len(df),
        'time_span': f"{df['date'].min().strftime('%Y-%m-%d')} to {df['date'].max().strftime('%Y-%m-%d')}",
        'phases': df['phase'].unique().tolist(),
        'session_types': df['session_type'].unique().tolist(),
        'expected_patterns': {
            'vocabulary_evolution': [
                'Early: accounting, meaningless, lost, job',
                'Middle: Python, algorithms, machine learning, neural networks', 
                'Late: neuroscience, research, AI ethics, brain-computer interfaces'
            ],
            'emotional_progression': [
                'Seeking (uncertain, lost, questioning)',
                'Discovery (excited, curious, alive)',
                'Development (learning, challenging, growing)',
                'Challenge (struggling, doubt, perseverance)',
                'Mastery (confident, purposeful, leading)',
                'Integration (teaching, mentoring, serving)',
                'Evolution (researching, visionary, pioneering)'
            ],
            'semantic_shifts': [
                'Session 7: Career transition (accounting â†’ data science)',
                'Session 12-14: Major challenge and recovery',
                'Session 16: Professional breakthrough',
                'Session 20-23: Shift to leadership and teaching',
                'Session 24+: Evolution toward research and AI ethics'
            ]
        }
    }
    
    return df, analysis_insights

def print_dataset_overview():
    """Print an overview of the demonstration dataset."""
    df, insights = load_demo_dataset()
    
    print("ğŸ¯ SEMANTIC TENSOR MEMORY DEMONSTRATION DATASET")
    print("=" * 60)
    print(f"ğŸ“Š Total Sessions: {insights['total_sessions']}")
    print(f"ğŸ“… Time Span: {insights['time_span']}")
    print(f"ğŸ”„ Phases: {', '.join(insights['phases'])}")
    print(f"ğŸ“ Session Types: {', '.join(insights['session_types'])}")
    
    print("\nğŸ§  EXPECTED SEMANTIC PATTERNS:")
    print("-" * 40)
    
    print("\nğŸ“š Vocabulary Evolution:")
    for i, stage in enumerate(insights['expected_patterns']['vocabulary_evolution'], 1):
        print(f"  {i}. {stage}")
    
    print("\nğŸ’­ Emotional Progression:")
    for phase in insights['expected_patterns']['emotional_progression']:
        print(f"  â€¢ {phase}")
    
    print("\nğŸš€ Key Semantic Shifts:")
    for shift in insights['expected_patterns']['semantic_shifts']:
        print(f"  â€¢ {shift}")
    
    print("\nğŸ¯ ANALYSIS OPPORTUNITIES:")
    print("-" * 40)
    print("âœ… Clear drift patterns across career transition")
    print("âœ… Vocabulary sophistication progression") 
    print("âœ… Emotional tone evolution")
    print("âœ… Conceptual complexity growth")
    print("âœ… Phase transition detection")
    print("âœ… Semantic clustering by life stages")
    print("âœ… Trajectory analysis showing development arc")

def get_streamlit_import_instructions():
    """Return instructions for importing into Streamlit app."""
    return """
    ğŸš€ TO IMPORT INTO STREAMLIT APP:
    
    1. Open your Semantic Tensor Memory app at http://localhost:8501
    2. In the sidebar, use "Import sessions from CSV"
    3. Upload the file: data/demo_dataset.csv
    4. The app will load 30 sessions showing a complete learning journey
    
    ğŸ”¬ RECOMMENDED ANALYSIS WORKFLOW:
    
    1. Start with "Drift Analysis" to see overall change patterns
    2. Try "Enhanced PCA Map" to visualize semantic evolution
    3. Use "Method Comparison" to find optimal dimensionality reduction
    4. Explore "Semantic Trajectory" for development path analysis
    5. Check "Ridgeline Plot" for feature evolution over time
    6. Use "Clinical Analysis & Chat" for AI insights
    
    ğŸ¯ WHAT TO LOOK FOR:
    
    â€¢ Clear semantic clusters corresponding to life phases
    â€¢ Vocabulary evolution from basic to technical terms
    â€¢ Emotional progression from uncertainty to confidence
    â€¢ Semantic "jumps" at major life transitions
    â€¢ Different dimensionality reduction methods revealing different patterns
    """

if __name__ == "__main__":
    print_dataset_overview()
    print(get_streamlit_import_instructions())
